# server
server.port=82
server.servlet.context-path=/jy-job

# database
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
spring.datasource.url=jdbc:mysql://10.128.62.33:3306/jy_example?serverTimezone=GMT%2B8
spring.datasource.username=root
spring.datasource.password=root
spring.datasource.initialSize=5
spring.datasource.minIdle=5
spring.datasource.maxActive=20
spring.datasource.maxWait=60000
spring.datasource.timeBetweenEvictionRunsMillis=60000
spring.datasource.minEvictableIdleTimeMillis=300000
spring.datasource.validationQuery=SELECT 1 FROM DUAL
spring.datasource.testWhileIdle=true
spring.datasource.testOnBorrow=false
spring.datasource.testOnReturn=false
spring.datasource.poolPreparedStatements=true
spring.datasource.maxPoolPreparedStatementPerConnectionSize=20
spring.datasource.filters=stat,wall
spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
mybatis-plus.mapper-locations=classpath:/mapper/*Mapper.xml
mybatis-plus.typeAliasesPackage=com.jy.entity

# redis
# Redis数据库索引（默认为0）
spring.redis.database=0
# Redis服务器地址
spring.redis.host=10.128.62.32
# Redis服务器连接端口
spring.redis.port=6379
# Redis服务器连接密码（默认为空）
spring.redis.password=
# 连接池最大连接数（使用负值表示没有限制）
spring.redis.jedis.pool.max-active=200
# 连接池最大阻塞等待时间（使用负值表示没有限制）
spring.redis.jedis.pool.max-wait=-1
# 连接池中的最大空闲连接
spring.redis.jedis.pool.max-idle=10
# 连接池中的最小空闲连接
spring.redis.jedis.pool.min-idle=0
# 连接超时时间（毫秒）
spring.redis.timeout=1000

# kafka
spring.kafka.bootstrap-servers=10.128.62.35:9092
# service
spring.kafka.producer.retries=0
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.properties.linger.ms=1
# consumer
spring.kafka.consumer.group-id=kafkaGroup
# 是否自动提交
spring.kafka.consumer.enable-auto-commit=true
# 自动提交时间间隔
spring.kafka.consumer.auto-commit-interval=100
# 实时生产，实时消费，不会从头开始消费
spring.kafka.consumer.auto.offset.reset=latest
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# 连接超时时间
spring.kafka.consumer.properties.session.timeout.ms=15000

# xxlJob
xxl.job.admin.addresses=http://localhost:8080/xxl-job-admin
# 其中ip可不填，会自动识别注册
xxl.job.executor.ip=
xxl.job.executor.port=9999
xxl.job.executor.logpath=D:/log
xxl.job.executor.appname=jy-job
xxl.job.accessToken=

# elasticsearch
# elasticsearch集群名称
spring.data.elasticsearch.cluster-name=prod_es_test
# 节点的地址
spring.data.elasticsearch.cluster-nodes=10.128.62.33:9300
# 是否开启本地存储
spring.data.elasticsearch.repositories.enabled=true
# http协议，用于外部通讯，防止actuator对elasticsearch健康检查失败
spring.elasticsearch.rest.uris=http://10.128.62.33:9200